{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUxKSz83o8SM+2MCmDKQ5z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebayuk/singtomeabelrepo/blob/main/singtomeabel2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##trying to figure out how to extract only the text from the weeknd json downloaded from hugging face so can then follow the video tutorial to create genai model"
      ],
      "metadata": {
        "id": "nGDoK7jhynYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/theweeknd.txt', 'r', encoding = 'utf-8', newline='\\n') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "XKLPy0Znq9EE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in text2[0:2]:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYHh36bjsFXX",
        "outputId": "a452ed91-5d8e-4667-e44a-7dd19a54302f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "Y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "regex = re.compile('[^a-zA-Z]')\n",
        "text2 = regex.sub(' ', text)"
      ],
      "metadata": {
        "id": "GT5z_-ACzI3E"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "regex = re.compile('[!\"#$%&()*,-./0123456789:;=?[\\n^{|}\\´ÀÁÇÜàáçèéêìíñòóôöùúüąćęğİıłńœśŞşźżƏəАСУХЧШабвгдежзийлмнорстухчшыьэүө–—‘’“”… イオガトブメラ]')\n",
        "text3 = regex.sub(' ', text)"
      ],
      "metadata": {
        "id": "35vkgcSf12kV"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P5rE9roh57Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trying to split out all the special characters\n",
        "\n",
        "newtext = []\n",
        "i = 0\n",
        "\n",
        "for count, value in enumerate(text2):\n",
        "  if value == 'n' and count+1 value\n",
        "    newtext.append(value+1)\n",
        "  else:\n",
        "    newtext.append(value)"
      ],
      "metadata": {
        "id": "Zwr6CndJzeMp"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#same as above\n",
        "chars2 = chars[1:]"
      ],
      "metadata": {
        "id": "jeicS9xbyj3_"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text2)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ey-8RtEyZB-",
        "outputId": "88168e7e-844c-4cce-b6b7-d161c9837f34"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = { ch:i for i,ch in enumerate(chars)}\n",
        "itos = { i:ch for i,ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "print(encode('hi there'))\n",
        "print(decode(encode('hi there')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwlVPxMu4JuM",
        "outputId": "8c46bec1-faff-43d2-fd26-32804038f46e"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[34, 35, 0, 46, 34, 31, 44, 31]\n",
            "hi there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encode datset into torch.tensor\n",
        "import torch\n",
        "data = torch.tensor(encode(text2), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22A04JUO7JTF",
        "outputId": "33edda3f-6e1c-41f7-9d77-db71afe8b414"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([896504]) torch.int64\n",
            "tensor([ 0, 25, 31, 27, 34,  0, 40, 25, 31, 27, 34,  0, 40, 25, 31, 27, 34,  0,\n",
            "        40, 25, 41, 47, 44,  0, 39, 27, 40,  0, 41, 40,  0, 46, 34, 31,  0, 44,\n",
            "        41, 27, 30,  0,  0, 34, 31,  0, 30, 41, 35, 40,  0, 42, 44, 41, 39, 41,\n",
            "         0, 40, 25, 41, 47,  0, 45, 27, 35, 30,  0,  0,  0,  0, 11, 31, 31, 42,\n",
            "         0, 41, 47, 44,  0, 28, 47, 45, 35, 40, 31, 45, 45,  0, 41, 40,  0, 46,\n",
            "        34, 31,  0, 38, 41, 49,  0, 38, 41, 49,  0,  0,  0, 40,  9, 39,  0, 36,\n",
            "        47, 45, 46,  0, 46, 44, 51, 40, 27,  0, 33, 31, 46,  0, 51, 41, 47,  0,\n",
            "        41, 47, 46,  0, 46, 34, 31,  0, 32, 44, 35, 31, 40, 30,  0, 52, 41, 40,\n",
            "        31,  0, 40,  3, 27, 47, 45, 31,  0, 51, 41, 47,  0, 38, 41, 41, 37,  0,\n",
            "        31, 48, 31, 40,  0, 28, 31, 46, 46, 31, 44,  0, 46, 34, 27, 40,  0, 46,\n",
            "        34, 31,  0, 42, 34, 41, 46, 41, 45,  0, 40,  9,  0, 29, 27, 40, 46,  0,\n",
            "        32, 35, 40, 30,  0, 51, 41, 47, 44,  0, 34, 41, 47, 45, 31,  0,  0, 45,\n",
            "        31, 40, 30,  0, 39, 31,  0, 46, 34, 31,  0, 35, 40, 32, 41,  0, 40,  4,\n",
            "        44, 35, 48, 35, 40,  0, 46, 34, 44, 41, 47, 33, 34,  0, 46, 34, 31,  0,\n",
            "        33, 27, 46, 31, 30,  0, 44, 31, 45, 35, 30, 31, 40, 46, 35, 27, 38,  0,\n",
            "        40,  6, 41, 47, 40, 30,  0, 41, 47, 46,  0,  9,  0, 49, 27, 45,  0, 29,\n",
            "        41, 39, 35, 40,  0,  0, 45, 31, 40, 46,  0, 51, 41, 47, 44,  0, 32, 44,\n",
            "        35, 31, 40, 30, 45,  0, 34, 41, 39, 31,  0, 40, 11, 31, 31, 42,  0, 41,\n",
            "        40,  0, 46, 44, 51, 40, 27,  0, 34, 35, 30, 31,  0, 35, 46,  0,  0, 28,\n",
            "        47, 46,  0, 51, 41, 47, 44,  0, 32, 44, 35, 31, 40, 30, 45,  0, 37, 40,\n",
            "        41, 49,  0, 40,  9,  0, 41, 40, 38, 51,  0, 29, 27, 38, 38,  0, 51, 41,\n",
            "        47,  0, 49, 34, 31, 40,  0, 35, 46, 45,  0, 34, 27, 38, 32,  0, 42, 27,\n",
            "        45, 46,  0, 32, 35, 48, 31,  0, 40, 20, 34, 31,  0, 41, 40, 38, 51,  0,\n",
            "        46, 35, 39, 31,  0, 46, 34, 27, 46,  0,  9, 38, 38,  0, 28, 31,  0, 28,\n",
            "        51,  0, 51, 41, 47, 44,  0, 45, 35, 30, 31,  0, 40,  9,  0, 41, 40, 38,\n",
            "        51,  0, 38, 41, 48, 31,  0, 35, 46,  0, 49, 34, 31, 40,  0, 51, 41, 47,\n",
            "         0, 46, 41, 47, 29, 34,  0, 39, 31,  0,  0, 40, 41, 46,  0, 32, 31, 31,\n",
            "        38,  0, 39, 31,  0, 40, 23, 34, 31, 40,  0,  9, 39,  0, 32, 47, 29, 37,\n",
            "        31, 30,  0, 47, 42,  0,  0, 46, 34, 27, 46, 45,  0, 46, 34, 31,  0, 44,\n",
            "        31, 27, 38,  0, 39, 31,  0, 40, 23, 34, 31, 40,  0,  9, 39,  0, 32, 47,\n",
            "        29, 37, 31, 30,  0, 47, 42,  0,  0, 46, 34, 27, 46, 45,  0, 46, 34, 31,\n",
            "         0, 44, 31, 27, 38,  0, 39, 31,  0,  0, 51, 31, 27, 34,  0, 40,  9,  0,\n",
            "        41, 40, 38, 51,  0, 29, 27, 38, 38,  0, 51, 41, 47,  0, 49, 34, 31, 40,\n",
            "         0, 35, 46, 45,  0, 34, 27, 38, 32,  0, 42, 27, 45, 46,  0, 32, 35, 48,\n",
            "        31,  0, 40, 20, 34, 31,  0, 41, 40, 38, 51,  0, 46, 35, 39, 31,  0,  9,\n",
            "        30,  0, 31, 48, 31, 44,  0, 29, 27, 38, 38,  0, 51, 41, 47,  0, 39, 35,\n",
            "        40, 31,  0, 40,  9,  0, 41, 40, 38, 51,  0, 38, 41, 48, 31,  0, 35, 46,\n",
            "         0, 49, 34, 31, 40,  0, 51, 41, 47,  0, 46, 41, 47, 29, 34,  0, 39, 31,\n",
            "         0,  0, 40, 41, 46,  0, 32, 31, 31, 38,  0, 39, 31,  0, 40, 23, 34, 31,\n",
            "        40,  0,  9, 39,  0, 32, 47, 29, 37, 31, 30,  0, 47, 42,  0,  0, 46, 34,\n",
            "        27, 46, 45,  0, 46, 34, 31,  0, 44, 31, 27, 38,  0, 39, 31,  0, 40, 23,\n",
            "        34, 31, 40,  0,  9, 39,  0, 32, 47, 29, 37, 31, 30,  0, 47, 42,  0,  0,\n",
            "        46, 34, 27, 46, 45,  0, 46, 34, 31,  0, 44, 31, 27, 38,  0, 39, 31,  0,\n",
            "         0, 28, 27, 28, 31,  0, 40,  9, 39, 27,  0, 38, 31, 46,  0, 51, 41, 47,\n",
            "         0, 37, 40, 41, 49,  0, 27, 40, 30,  0, 37, 31, 31, 42,  0, 35, 46,  0,\n",
            "        45, 35, 39, 42, 38, 31,  0, 40, 20, 44, 51, 40, 27,  0, 37, 31, 31, 42,\n",
            "         0, 35, 46,  0, 47, 42,  0, 30, 41, 40, 46,  0, 45, 31, 31, 39,  0, 45,\n",
            "        41,  0, 45, 35, 39, 42, 38, 31,  0, 40,  9,  0, 36, 47, 45, 46,  0, 32,\n",
            "        47, 29, 37, 31, 30,  0, 46, 49, 41,  0, 28, 35, 46, 29, 34, 31, 45,  0,\n",
            "        32, 41, 44, 31,  0,  9,  0, 45, 27, 49,  0, 51, 41, 47,  0, 40,  1, 40,\n",
            "        30,  0, 51, 41, 47,  0, 33, 41, 40,  0, 34, 27, 48, 31,  0, 46, 41,  0,\n",
            "        30, 41,  0, 35, 46,  0, 27, 46,  0, 39, 51,  0, 46, 31, 39, 42, 41,  0,\n",
            "        40,  1, 38, 49, 27, 51, 45,  0, 46, 44, 51, 40, 27,  0, 45, 31, 40, 30,\n",
            "         0, 39, 31,  0, 41, 32, 32,  0, 46, 41,  0, 44, 31, 34, 27, 28,  0, 40,\n",
            "         4, 44, 47, 33, 45,  0, 45, 46, 27, 44, 46, 31, 30,  0, 32, 31, 31, 38,\n",
            "        35, 40,  0, 38, 35, 37, 31,  0, 35, 46])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into train test\n",
        "n = int((0.9)*len(data))\n",
        "traindata = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "C8UuE-qk7jEN"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "traindata[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7Fi-qKL8DkS",
        "outputId": "dc5e2d3d-d5b4-40f6-82bf-2fe6a8f3368b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 25, 31, 27, 34,  0, 40, 25, 31])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how we will train the data\n",
        "x = traindata[:block_size]\n",
        "y = traindata[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f'when input is {context} the target: {target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcvLnd5D8m2E",
        "outputId": "ffc982b0-2012-45a4-87fa-53371031a382"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([0]) the target: 25\n",
            "when input is tensor([ 0, 25]) the target: 31\n",
            "when input is tensor([ 0, 25, 31]) the target: 27\n",
            "when input is tensor([ 0, 25, 31, 27]) the target: 34\n",
            "when input is tensor([ 0, 25, 31, 27, 34]) the target: 0\n",
            "when input is tensor([ 0, 25, 31, 27, 34,  0]) the target: 40\n",
            "when input is tensor([ 0, 25, 31, 27, 34,  0, 40]) the target: 25\n",
            "when input is tensor([ 0, 25, 31, 27, 34,  0, 40, 25]) the target: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#going to feed batches of these chunks of texts into the transformer\n",
        "torch.manual_seed(1333)\n",
        "batch_size = 4 #how many independent sequences will we process in parallel\n",
        "block_size = 8 #what is the maximum context length for predictions\n",
        "\n",
        "def get_batch(split):\n",
        "  #generate a small batch of data of inputs x and targets y\n",
        "  data = traindata if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size):\n",
        "  for t in range(block_size):\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f'when input is {context.tolist()} the target: {target}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUTF5bU39Igw",
        "outputId": "94f0dc7b-8f16-4545-ae13-138e6fc9db38"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[47,  0, 39, 27, 37, 31,  0, 35],\n",
            "        [31, 46, 31, 38, 51,  0, 41, 32],\n",
            "        [51, 41, 47,  0, 28, 35, 46, 31],\n",
            "        [35, 41, 40, 45,  0, 49, 31, 44]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[ 0, 39, 27, 37, 31,  0, 35, 46],\n",
            "        [46, 31, 38, 51,  0, 41, 32, 32],\n",
            "        [41, 47,  0, 28, 35, 46, 31,  0],\n",
            "        [41, 40, 45,  0, 49, 31, 44, 31]])\n",
            "----\n",
            "when input is [47] the target: 0\n",
            "when input is [47, 0] the target: 39\n",
            "when input is [47, 0, 39] the target: 27\n",
            "when input is [47, 0, 39, 27] the target: 37\n",
            "when input is [47, 0, 39, 27, 37] the target: 31\n",
            "when input is [47, 0, 39, 27, 37, 31] the target: 0\n",
            "when input is [47, 0, 39, 27, 37, 31, 0] the target: 35\n",
            "when input is [47, 0, 39, 27, 37, 31, 0, 35] the target: 46\n",
            "when input is [31] the target: 46\n",
            "when input is [31, 46] the target: 31\n",
            "when input is [31, 46, 31] the target: 38\n",
            "when input is [31, 46, 31, 38] the target: 51\n",
            "when input is [31, 46, 31, 38, 51] the target: 0\n",
            "when input is [31, 46, 31, 38, 51, 0] the target: 41\n",
            "when input is [31, 46, 31, 38, 51, 0, 41] the target: 32\n",
            "when input is [31, 46, 31, 38, 51, 0, 41, 32] the target: 32\n",
            "when input is [51] the target: 41\n",
            "when input is [51, 41] the target: 47\n",
            "when input is [51, 41, 47] the target: 0\n",
            "when input is [51, 41, 47, 0] the target: 28\n",
            "when input is [51, 41, 47, 0, 28] the target: 35\n",
            "when input is [51, 41, 47, 0, 28, 35] the target: 46\n",
            "when input is [51, 41, 47, 0, 28, 35, 46] the target: 31\n",
            "when input is [51, 41, 47, 0, 28, 35, 46, 31] the target: 0\n",
            "when input is [35] the target: 41\n",
            "when input is [35, 41] the target: 40\n",
            "when input is [35, 41, 40] the target: 45\n",
            "when input is [35, 41, 40, 45] the target: 0\n",
            "when input is [35, 41, 40, 45, 0] the target: 49\n",
            "when input is [35, 41, 40, 45, 0, 49] the target: 31\n",
            "when input is [35, 41, 40, 45, 0, 49, 31] the target: 44\n",
            "when input is [35, 41, 40, 45, 0, 49, 31, 44] the target: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1333)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets):\n",
        "    #logits = score for next token in the sequence\n",
        "    logits = self.token_embedding_table(idx) #B, T, C\n",
        "\n",
        "    B,T,C = logits.shape\n",
        "    logits = logits.view(B*T, C)\n",
        "    targets = targets.view(B*T)\n",
        "    loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ktujc9izBds2",
        "outputId": "9463ccb2-1950-41f3-b75b-0414f69b97cb"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 53])\n",
            "tensor(4.4319, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KgWFAFBFDd_F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}